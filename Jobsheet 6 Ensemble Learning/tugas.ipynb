{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas 1\n",
    "\n",
    "Terdapat dataset mushroom. Berdasarkan dataset yang tersebut, bandingkan peforma antara algoritma Decision Tree dan RandomForest. Gunakan tunning hyperparameter untuk mendapatkan parameter dan akurasi yang terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n",
      "Decision Tree Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00      1052\n",
      "           p       1.00      1.00      1.00       979\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n",
      "Random Forest Accuracy: 1.0\n",
      "Random Forest Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00      1052\n",
      "           p       1.00      1.00      1.00       979\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "mushroom_data = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "# Pisahkan fitur dan label\n",
    "X = mushroom_data.drop('class', axis=1)\n",
    "y = mushroom_data['class']\n",
    "\n",
    "# Encode data kategorikal menjadi numerik\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Tuning hyperparameter untuk Decision Tree\n",
    "dt_params = {'max_depth': [5, 10, 15, 20], 'min_samples_split': [2, 5, 10]}\n",
    "dt = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=5)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_best = dt.best_estimator_\n",
    "\n",
    "# Tuning hyperparameter untuk Random Forest\n",
    "rf_params = {'n_estimators': [50, 100], 'max_depth': [10, 20, None]}\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_best = rf.best_estimator_\n",
    "\n",
    "# Evaluasi performa\n",
    "y_pred_dt = dt_best.predict(X_test)\n",
    "y_pred_rf = rf_best.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Decision Tree Report:\\n\", classification_report(y_test, y_pred_dt))\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penjelasan:\n",
    "Membandingkan performa Decision Tree dan Random Forest dengan tuning hyperparameter menggunakan GridSearchCV.\n",
    "\n",
    "- Tujuan: Membandingkan akurasi dan performa dari dua algoritma:\n",
    "    Decision Tree: Model berbasis pohon keputusan yang memilih fitur secara rekursif untuk membagi data berdasarkan impuritas (misalnya Gini atau Entropy).\n",
    "    Random Forest: Kumpulan banyak pohon keputusan dengan teknik bagging untuk meningkatkan generalisasi dan mengurangi overfitting.\n",
    "\n",
    "- Langkah Tuning Hyperparameter:\n",
    "    Decision Tree: Dicari kombinasi terbaik untuk max_depth (kedalaman maksimum) dan min_samples_split (minimal sampel agar terjadi pembagian).\n",
    "    Random Forest: Dicari kombinasi terbaik untuk jumlah pohon (n_estimators) dan kedalaman pohon (max_depth).\n",
    "\n",
    "- Evaluasi:\n",
    "    Akurasi dan laporan klasifikasi ditampilkan untuk membandingkan performa kedua model.\n",
    "    Random Forest biasanya lebih akurat daripada Decision Tree karena menggunakan banyak pohon yang mengurangi risiko overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas 2\n",
    "\n",
    "Bandingkan performa antara Decision Tree dan AdaBoost menggunakan dataset mushroom, dengan tuning hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 1.0\n",
      "AdaBoost Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00      1052\n",
      "           p       1.00      1.00      1.00       979\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Tuning hyperparameter untuk AdaBoost\n",
    "ab_params = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1, 1.0]}\n",
    "ab = GridSearchCV(AdaBoostClassifier(random_state=42), ab_params, cv=5)\n",
    "ab.fit(X_train, y_train)\n",
    "ab_best = ab.best_estimator_\n",
    "\n",
    "# Evaluasi performa\n",
    "y_pred_ab = ab_best.predict(X_test)\n",
    "\n",
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, y_pred_ab))\n",
    "print(\"AdaBoost Report:\\n\", classification_report(y_test, y_pred_ab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penjelasan\n",
    "Membandingkan performa Decision Tree dan AdaBoost dengan metode yang sama.\n",
    "\n",
    "- Tujuan: Membandingkan performa antara:\n",
    "    Decision Tree: Model sederhana dan cepat, tetapi rentan terhadap overfitting.\n",
    "    AdaBoost: Teknik boosting yang membangun model secara iteratif, menekankan pada sampel yang sulit diklasifikasikan dalam iterasi sebelumnya.\n",
    "\n",
    "- Langkah Tuning Hyperparameter:\n",
    "    Decision Tree: Parameter sama seperti pada Tugas 1.\n",
    "    AdaBoost: Hyperparameter yang dicari:\n",
    "        n_estimators: Jumlah estimator (pohon) dalam ensemble.\n",
    "        learning_rate: Mengontrol kontribusi masing-masing pohon.\n",
    "\n",
    "- Evaluasi:\n",
    "Model AdaBoost sering memberikan akurasi lebih tinggi karena memperkuat sampel yang sulit diklasifikasikan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas 3\n",
    "\n",
    "Buat ensemble voting menggunakan Logistic Regression, SVM dengan kernel polynomial, dan Decision Tree menggunakan dataset diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.7760416666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       125\n",
      "           1       0.73      0.57      0.64        67\n",
      "\n",
      "    accuracy                           0.78       192\n",
      "   macro avg       0.76      0.73      0.74       192\n",
      "weighted avg       0.77      0.78      0.77       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset diabetes\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Pisahkan fitur dan label\n",
    "X = diabetes.drop('Outcome', axis=1)\n",
    "y = diabetes['Outcome']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definisikan model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "svm = SVC(kernel='poly', probability=True, random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Ensemble voting\n",
    "voting_clf = VotingClassifier(estimators=[('lr', logreg), ('svc', svm), ('dt', dt)], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi performa\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "print(\"Voting Classifier Accuracy:\", accuracy_score(y_test, y_pred_voting))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penjelasan\n",
    "Menggabungkan Logistic Regression, SVM dengan kernel polynomial, dan Decision Tree dalam ensemble voting. Standarisasi digunakan untuk memastikan SVM bekerja optimal.\n",
    "\n",
    "- Tujuan: Membuat ensemble voting dengan tiga algoritma:\n",
    "    Logistic Regression: Model sederhana dan linier, cocok untuk klasifikasi biner.\n",
    "    SVM dengan kernel polynomial: Mampu menangani data non-linier dengan proyeksi ke dimensi lebih tinggi.\n",
    "    Decision Tree: Model berbasis pohon yang menangkap hubungan non-linier.\n",
    "\n",
    "- Langkah Tuning Hyperparameter:\n",
    "    Hyperparameter dari tiap model bisa dieksplorasi (seperti kernel pada SVM, atau kedalaman pada Decision Tree).\n",
    "    VotingClassifier: Voting bisa diatur dalam dua mode:\n",
    "        Hard Voting: Berdasarkan mayoritas prediksi.\n",
    "        Soft Voting: Berdasarkan probabilitas dari masing-masing model.\n",
    "\n",
    "- Evaluasi:\n",
    "    Standarisasi Data: Dilakukan karena SVM sangat sensitif terhadap skala data.\n",
    "    Akurasi dan Laporan Klasifikasi: Digunakan untuk mengukur performa ensemble dan mengevaluasi model mana yang memiliki performa terbaik."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
